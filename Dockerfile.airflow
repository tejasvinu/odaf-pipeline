FROM apache/airflow:2.5.0

USER root
RUN apt-get update && \
    apt-get install -y \
    netcat-traditional \
    netcat \
    wget \
    kafkacat \
    procps \
    curl && \
    wget https://dl.min.io/client/mc/release/linux-amd64/mc && \
    chmod +x mc && \
    mv mc /usr/local/bin/ && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    mkdir -p /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins /opt/airflow/config && \
    chown -R airflow:root /opt/airflow && \
    # Create nc symlink if it doesn't exist
    if [ ! -f /usr/bin/nc ]; then ln -s /usr/bin/netcat /usr/bin/nc; fi

# Install Java correctly
RUN apt-get update && \
    apt-get install -y openjdk-11-jdk && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Set JAVA_HOME environment variable properly
ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV PATH="$JAVA_HOME/bin:${PATH}"

# Create symlink and verify Java installation
RUN ln -sf /usr/lib/jvm/java-11-openjdk-amd64 /usr/lib/jvm/default-java && \
    echo "Symlinked java-11-openjdk-amd64 to /usr/lib/jvm/default-java" && \
    which java && \
    java -version && \
    ln -s /bin/ps /usr/bin/ps 2>/dev/null || true && \
    # Make Java environment globally available
    echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64" >> /etc/profile && \
    echo "export PATH=$JAVA_HOME/bin:$PATH" >> /etc/profile && \
    # Make Java environment available to airflow user
    echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64" >> /home/airflow/.bashrc && \
    echo "export PATH=$JAVA_HOME/bin:$PATH" >> /home/airflow/.bashrc

# Copy the verification script and create the entrypoint
COPY verify_environment.sh /opt/airflow/verify_environment.sh.orig
COPY airflow-entrypoint.sh /entrypoint.sh

# Create a safer wrapper script for verify_environment.sh
RUN echo '#!/bin/bash' > /usr/local/bin/verify_env && \
    echo 'set +e  # Do not exit on error' >> /usr/local/bin/verify_env && \
    echo 'if [ -f /opt/airflow/verify_environment.sh ]; then' >> /usr/local/bin/verify_env && \
    echo '  bash /opt/airflow/verify_environment.sh "$@" || echo "Verification script completed with non-zero exit code"' >> /usr/local/bin/verify_env && \
    echo 'else' >> /usr/local/bin/verify_env && \
    echo '  echo "Using built-in verification script"' >> /usr/local/bin/verify_env && \
    echo '  bash /opt/airflow/verify_environment.sh.orig "$@" || echo "Verification script completed with non-zero exit code"' >> /usr/local/bin/verify_env && \
    echo 'fi' >> /usr/local/bin/verify_env && \
    chmod +x /usr/local/bin/verify_env

# Convert line endings and make scripts executable
RUN sed -i 's/\r$//' /opt/airflow/verify_environment.sh.orig && \
    sed -i 's/\r$//' /entrypoint.sh && \
    chmod +x /opt/airflow/verify_environment.sh.orig && \
    chmod +x /entrypoint.sh

# Explicitly set directory permissions
RUN mkdir -p /opt/airflow/{logs,dags,plugins,config,downloads} && \
    chmod -R 777 /opt/airflow/logs /opt/airflow/dags /opt/airflow/plugins /opt/airflow/config /opt/airflow/downloads && \
    touch /opt/airflow/.airflowignore && chmod 644 /opt/airflow/.airflowignore

USER airflow

# Ensure the correct Airflow installation with better error handling and retry logic
RUN pip install --upgrade pip && \
    pip config set global.timeout 1000 && \
    pip config set global.retries 10 && \
    # Explicitly download the constraint file first to avoid network issues
    wget -O /tmp/constraints.txt "https://raw.githubusercontent.com/apache/airflow/constraints-2.5.0/constraints-3.7.txt" && \
    # Explicitly reinstall airflow to fix potential installation issues
    pip install --no-cache-dir "apache-airflow==2.5.0" --constraint "/tmp/constraints.txt" && \
    # Verify installation
    python -c "import airflow; print(f'Installed Airflow version: {airflow.__version__}')" && \
    # Clean up constraint file
    rm -f /tmp/constraints.txt

# Verify Airflow installation
RUN airflow version

# Install smaller packages first
RUN pip install --no-cache-dir \
    boto3 \
    kafka-python \
    requests

# Install PySpark separately with a specific version
RUN pip install --no-cache-dir pyspark==3.3.2

# Install Airflow provider package
RUN pip install --no-cache-dir apache-airflow-providers-apache-spark==4.1.0
    
# Add Java and Airflow paths for airflow user's shell
RUN echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64" >> ~/.bashrc && \
    echo "export PATH=/home/airflow/.local/bin:\$JAVA_HOME/bin:\$PATH" >> ~/.bashrc

# Make sure airflow is in the PATH
ENV PATH="/home/airflow/.local/bin:${PATH}"

# Set workdir to airflow home
WORKDIR /opt/airflow

# Use our custom entrypoint
ENTRYPOINT ["/entrypoint.sh"]